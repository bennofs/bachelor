\documentclass[aspectratio=169,xcolor=usenames,dvipsnames,svgnames]{beamer}

\usepackage{fontspec}
\usepackage{appendixnumberbeamer}
\usepackage{tikz}
\usepackage{varwidth}
\usepackage{pstricks}
\usepackage{polyglossia}
\usepackage{csquotes}
\usepackage{xsavebox}
\usepackage{pifont}
\usepackage{xurl}
\usepackage[style=authoryear]{biblatex}
\usepackage{pgfplots}
%\usepackage[shortlabels]{enumitem}

\setmainlanguage{german}
\MakeOuterQuote{"}

\usetheme[numbering=fraction]{metropolis}
\setsansfont[BoldFont={Fira Sans SemiBold}]{Fira Sans Book}
\metroset{block=fill}

\usetikzlibrary{patterns}
\usetikzlibrary{shapes}
\usetikzlibrary{shapes.symbols}
\usetikzlibrary{positioning}
\usetikzlibrary{fit}
\usetikzlibrary{backgrounds}
\usetikzlibrary{calc}

\pgfplotsset{compat=1.16}
\usepgfplotslibrary[dateplot]

\newcommand{\tikzdbg}{%
  \draw[step=1,color=lightgray] (-7,0) grid (10,10);%
  \fill[red] (0,0) circle (0.2);%
}

\tikzset{
  onslide/.code args={<#1>#2}{%
    \only<#1>{\pgfkeysalso{#2}}% \pgfkeysalso doesn't change the path
  },
  temporal/.code args={<#1>#2#3#4}{%
    \temporal<#1>{\pgfkeysalso{#2}}{\pgfkeysalso{#3}}{\pgfkeysalso{#4}}%
  },
  hidden/.style = {opacity=0},
  uncover/.style = {temporal=#1{hidden}{}{hidden}},
  drawalert/.style = {temporal=#1{}{color=alerted text.fg}{}}
}

\input{tikz/colors}

\newenvironment{tikzcomponent}[1]{%
  \begin{xlrbox}{#1}%
    \begin{tikzpicture}%
    }{
    \end{tikzpicture}%
  \end{xlrbox}%
}

\newcommand{\TODO}[1]{
  \red{TODO: #1}
}

\bibliography{./bib-refs.bib}

\typeout{CONTENT START NOW}

\title{Generierung angepasster RDF-Dumps von Wikidata}
\subtitle{Bachelorverteidigung}
\date{16. Januar 2020}
\author{Benno Fünfstück}
\institute{Betreuer: Prof. Dr. Markus Krötzsch \\ Wissensbasierte Systeme \\ TU Dresden}

\begin{document}

%\includeonlyframes{first,current}
    
\begin{frame}[label=first]
  \input{./tikz/symbols}
  \maketitle
\end{frame}

\setbeamertemplate{frame footer}[custom]{%
  Bachelorverteidigung: \insertshortauthor
}

\begin{frame}
  \centering
  \includegraphics[width=0.6\textwidth]{./pics/Wikidata-logo-en} \\
  "Die freie Wissensdatenbank mit 74.018.298 Datensätzen, die jeder bearbeiten kann."
\end{frame}

\begin{frame}\frametitle{Wikidata: Items}
  \input{./tikz/item-head}
\end{frame}

\begin{frame}\frametitle{Wikidata: Statements}
  \input{./tikz/item-stmts}
\end{frame}


\section{Idee: Tool zum Filtern der Daten}

% \begin{frame}[fragile]\frametitle{Beispiele}
%   GraFa: Faceted Search \& Browsing for the Wikidata Knowledge Graph \\
%   (\cite{usage-grafa}) \\
% nur "truthy" Statements mit Entitäten als Objekt;
%   Labels/Descriptions nur in Englisch und Spanisch \\
%   \vspace{0.5cm}

%   Populating Narratives Using Wikidata Events: An Initial Experiment \\
%   (\cite{usage-narratives}) \\
%   alle  Items mit einem Statement für mindestens eine von 50 festgelegten
%   Properties
% \end{frame}

\begin{frame}{Anforderungen}
  \alert{\textbf{Filterung:}} Einen Dump aus einer Teilmenge der Daten erzeugen, nach
  nutzerdefinierten \emph{Kriterien}

  Diese Dumps sollen \textbf{archiviert} werden und das Archiv \textbf{durchsuchbar} sein.

  \pause

  Anforderungen an das Interface:
  \begin{itemize}
      \item Prozess ist \textbf{nachvollziehbar}: Ursprung, Inhalt des Dumps
      \item Feedback zu \textbf{Fortschritt}
      \item mehrere Nutzer können parallel Dumps erzeugen (\textbf{Parallelverarbeitung})
  \end{itemize}

  \pause

  Format der Dumps: \emph{RDF (Resource Description Framework)}
\end{frame}


\begin{frame}[label=current]\frametitle{Filterkriterien}
  Konzeptionell drei Ebenen:
  \begin{itemize}
    \item Auswahl der Items
    \item Auswahl der Statements
    \item Export des Statements
  \end{itemize}

  Unabhängig davon: Labels, Descriptions, Aliases, Sitelinks, Sprache von Literalen
\end{frame}


\begin{frame}[t, fragile]\frametitle{Wikidata als RDF}
  \begin{block}{Beispiel}
  \begin{verbatim}
 wd:Q42 rdfs:label "Douglas Adams"@en .
 wd:Q42 rdfs:label "Douglas Adams"@de .
  \end{verbatim}
    \vspace{-0.2cm}
  \end{block}

  \begin{block}{Einfache Darstellung: ein Tripel für jedes Statement}
  \begin{verbatim}
 wd:Q42 wdt:P69 wd:Q691283 .
 wd:Q42 wdt:P69 wd:Q4961791.
  \end{verbatim}
    \vspace{-0.2cm}
  \end{block}

  \textbf{Aber:} Ranks, Qualifier, Komplexe Werte?
  %\footnotesize{\verb|wd:Q42| ist kurz für \verb|<http://www.wikidata.org/entity/Q42>|}
\end{frame}

\begin{frame}[t, fragile]\frametitle{Wikidata als RDF: Reifikation}
  \vspace{-0.15cm}
  \input{tikz/reifikation}
\end{frame}

% \begin{frame}[t, fragile]\frametitle{Wikidata als RDF: Reifikation}
%   \vspace{0.25cm}
%   \begin{block}{RDF}
%   \begin{verbatim}
%  wd:Q42 p:P69 wds:q42-xxxx .
%  wds:Q42-xxxx rdf:type wikibase:Statement .
%  wds:Q42-xxxx ps:P69 wd:Q4961791 .
%  wds:Q42-xxxx pq:P580 "1959-01-01T00:00:00Z"^^xds:dateTime .
%  wds:Q42-xxxx pqv:P580 wdv:aaaaaaaa .
%  wds:Q42-xxxx pq:P582 "1970-01-01T00:00:00Z"^^xsd:dateTime .
%  wds:Q42-xxxx pqv:P582 wdv:bbbbbbbb .
%  wd:Q42 wdt:P69 wd:Q4961791.
%   \end{verbatim}
%   \end{block}
% \end{frame}

\section{Umsetzung}

\begin{frame}\frametitle{Ansatz: Wikidata Query Service}
  \emph{Wikidata Query Service} indiziert den RDF-Export von Wikidata und
  beantwortet SPARQL-Abfragen über diesen Datensatz.

  \textbf{Vorteile:}
  \begin{itemize}
    \item Kann einige Abfragen sehr schnell beantworten
    \item Verwendet aktuelle Daten
  \end{itemize}
  \textbf{Nachteile:}
  \begin{itemize}
    \item Große Dumps führen zu Timeout
    \item Formulierung der Filter in SPARQL umständlich
  \end{itemize}

\end{frame}

\begin{frame}\frametitle{Ansatz: Wikidata Toolkit}
  \emph{Wikidata Toolkit} ist eine Java-Bibliothek zum Verarbeiten der JSON-Exporte von Wikidata.
  \begin{itemize}
      \item Implementiert das RDF Dump Format
      \item Wird aktiv entwickelt
  \end{itemize}

  \textbf{Vorteile:}
  \begin{itemize}
    \item Kann auch sehr große Dumps erzeugen
    \item Filter können in Java geschrieben werden

  \end{itemize}

  \textbf{Nachteile:}
  \begin{itemize}
      \item Langsamer als index-basierte Methoden
      \item Verwendet nicht den "offiziellen" RDF-Export von Wikidata
  \end{itemize}


\end{frame}

\begin{frame}\frametitle{System}
  \begin{figure}
    \input{./tikz/arch}
  \end{figure}
\end{frame}

\begin{frame}[plain, fragile]
  \centering
  \begin{columns}
    \begin{column}{0.65\framewidth}
      \includegraphics[width=0.65\framewidth]{./pics/screen-main}
    \end{column}
    \begin{column}{0.35\framewidth}
      Deployment auf Toolforge \\
      \vspace{0.5cm}
      Backend in Java \\
      \vspace{0.5cm}
      Frontend in Python/TypeScript \\
      \vspace{0.5cm}
      MariaDB als Datenbank \\
      \vspace{0.5cm}
      \hspace{-110pt}
      \color{blue!80!black}{\url{https://tools.wmflabs.org/wdumps}}
    \end{column}
  \end{columns}
\end{frame}

\section{Evaluation}

\begin{frame}[t]
  \only<1>{\includegraphics[width=\framewidth]{./pics/uiwalk/1.png}}
  \only<2>{\includegraphics[width=\framewidth]{./pics/uiwalk/2.png}}
  \only<3>{\includegraphics[width=\framewidth]{./pics/uiwalk/3.png}}
  \only<4>{\includegraphics[width=\framewidth]{./pics/uiwalk/5.png}}
  \only<5>{\includegraphics[width=\framewidth]{./pics/uiwalk/6.png}}
  \only<6>{\includegraphics[width=\framewidth]{./pics/uiwalk/7.png}}
  \only<7>{\includegraphics[width=\framewidth]{./pics/uiwalk/8.png}}
\end{frame}

\begin{frame}\frametitle{Korrektheit}
  Die Anwendung verwendet Wikidata Toolkit zur Generierung der RDF-Daten \\

  \begin{center}
  \begin{tikzpicture}
    \def\lwidth{0.02in};

    \node[scale=0.6] (database) at (0, 0) {\thedatabase};
    \node[right of=database, node distance=2.2cm, inner xsep=0.25cm] (databasetext) {\small{Wikidata Datenbank}};

    \begin{scope}[yshift=-2.7cm, xshift=-0.5cm]
     \def\corner{0.15in};
     \def\cornerradius{0.02in};
     \def\h{1.7cm};
     \def\w{1.5cm};
     \foreach \i in {0,1,2} {
     \coordinate (nw) at ($(-0.05in*\i,-0.06in*\i)$);
     \coordinate (ne0) at ($(nw) + (\w, 0)$);
     \coordinate (ne1) at ($(ne0) - (\corner, 0)$);
     \coordinate (ne2) at ($(ne0) - (0, \corner)$);
     \coordinate (se) at ($(ne0) + (0, -\h)$);
     \filldraw [-, line width = \lwidth, fill=white] (nw) -- (ne1) -- (ne2)
     [rounded corners=\cornerradius]--(se) -- (nw|-se) -- cycle;
     \draw [-, line width = \lwidth] (ne1) [rounded corners=\cornerradius]-- (ne1|-ne2) -- (ne2);
     }
     \node[anchor=north west,node distance=0] at (-0.05in,-0.8) {JSON};
    \end{scope}

    \begin{scope}[xshift=8cm, yshift=1cm]
     \def\corner{0.15in};
     \def\cornerradius{0.02in};
     \def\h{1.7cm};
     \def\w{1.5cm};
     \foreach \i in {0,1,2} {
     \coordinate (nw) at ($(-0.05in*\i,-0.06in*\i)$);
     \coordinate (ne0) at ($(nw) + (\w, 0)$);
     \coordinate (ne1) at ($(ne0) - (\corner, 0)$);
     \coordinate (ne2) at ($(ne0) - (0, \corner)$);
     \coordinate (se) at ($(ne0) + (0, -\h)$);
     \filldraw [-, line width = \lwidth, fill=white] (nw) -- (ne1) -- (ne2)
     [rounded corners=\cornerradius]--(se) -- (nw|-se) -- cycle;
     \draw [-, line width = \lwidth] (ne1) [rounded corners=\cornerradius]-- (ne1|-ne2) -- (ne2);
     }
     \node[anchor=north west,node distance=0] at (-0.05in,-0.8) {RDF 1};
    \end{scope}

    \begin{scope}[xshift=8cm, yshift=-2.7cm]
     \def\corner{0.15in};
     \def\cornerradius{0.02in};
     \def\h{1.7cm};
     \def\w{1.5cm};
     \foreach \i in {0,1,2} {
     \coordinate (nw) at ($(-0.05in*\i,-0.06in*\i)$);
     \coordinate (ne0) at ($(nw) + (\w, 0)$);
     \coordinate (ne1) at ($(ne0) - (\corner, 0)$);
     \coordinate (ne2) at ($(ne0) - (0, \corner)$);
     \coordinate (se) at ($(ne0) + (0, -\h)$);
     \filldraw [-, line width = \lwidth, fill=white] (nw) -- (ne1) -- (ne2)
     [rounded corners=\cornerradius]--(se) -- (nw|-se) -- cycle;
     \draw [-, line width = \lwidth] (ne1) [rounded corners=\cornerradius]-- (ne1|-ne2) -- (ne2);
     }
     \node[anchor=north west,node distance=0] at (-0.05in,-0.8) {RDF 2};
    \end{scope}

    \draw[->, very thick] (-0,-0.9cm) to node[sloped, above]{export} (-0, -2.5cm);
    \draw[->, very thick] (databasetext.east) to node[above, inner xsep=0.5cm]{export} (7.25, 0);
    \draw[->, very thick] (1.5, -3.75) to node[above, inner xsep=0.5cm]{Wikidata Toolkit} (7.25, -3.75);

    \draw[<->, very thick, alert] (8.5, -1.2) to node[above, anchor=west] {???} (8.5, -2.5);
  \end{tikzpicture}
  \end{center}
\end{frame}

\begin{frame}{Ergebnis}
  Es wurden eine Reihe von Fehlern im RDF-Export von Wikidata Toolkit gefunden:
  \begin{itemize}
    \item andere Schreibweisen
    \item minimal andere Struktur
    \item besonders bei komplexen Typen (Zeitpunkte, Orte)
  \end{itemize}

  Beispiele für weniger offensichtliche Fehler sind:
  \begin{itemize}
      \item Vertauschung von Koordinaten bei Orten
      \item falsche Deduplizierung bei Value-Nodes
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Ergebnis: falsche Deduplizierung bei Werten mit Präzisionsangabe}
  Für Zeit- und Ortsangaben kann die Präzision gespeichert werden \\
  \begin{center}
  \begin{tikzpicture}
    \node (header1) {\bfseries TimeValue 1};
    \node[below=of header1.west, anchor=west] (value1) {+1976-01-12T00:00:00Z};
    \node[below=of value1.west, anchor=west, onslide=<1>{red}] (precision1) {Präzision: 9 (Jahr)};
    \node[fit={(header1) (value1) (precision1)}, rectangle, draw] (tv1) {};

    \begin{scope}[temporal=<2->{}{color=gray}{}]
      \node[right=3cm of header1] (header2) {\bfseries TimeValue 2};
      \node[below=of header2.west, anchor=west] (value2) {+1976-01-12T00:00:00Z};
      \node[below=of value2.west, anchor=west, onslide=<1>{red}] (precision2) {Präzision: 11 (Tag)};
      \node[temporal=<2->{}{dashed}{}, fit={(header2) (value2) (precision2)}, rectangle, draw] (tv2) {};
    \end{scope}

    \node[below=2cm of tv1, ellipse, draw] (A) {A};
    \node[below=2cm of tv2, ellipse, draw] (B) {B};

    \draw[->, thick] (A) -- (tv1);
    \draw[->, thick, temporal=<2->{}{opacity=0,dashed}{}] (B) -- (tv2);

    \draw[->, thick, uncover=<2->, drawalert=<2->] (B) -- (tv1.south);
    \node[uncover=<2->, drawalert=<2->, above=of B, node distance=0.5cm] {Präzision nicht beachtet};

  \end{tikzpicture}
  \end{center}
\end{frame}

\begin{frame}{Fazit}
  \setbeamertemplate{enumerate items}[circle]
  \textbf{Ergebnis:}
  \begin{enumerate}
      \item Erfolgreiche Implementierung eines funktionsfähigen Prototyps
      \item RDF-Export von Wikidata Toolkit verbessert
      \item Gesamter Quellcode ist offen verfügbar: \url{https://github.com/bennofs/wdumper}
  \end{enumerate}

  \textbf{Ausblick:}
  \setbeamertemplate{enumerate items}[default]
  \begin{itemize}
      \item Weitere Kriterien zum Filtern: SPARQL, zufällige Auswahl, Anzahl an
      Sitelinks, \ldots
      \item Verbesserung des UI: Vorschau, vorgeschlagene Dumps, bessere Suche
  \end{itemize}
  % \pause
  % \vspace{1cm}
  % \centering
  % {\LARGE Fragen?}
\end{frame}

\appendix

\begin{frame}\frametitle{Wikidata: Größe}
  \begin{tikzpicture}
    \begin{axis}[
      date coordinates in=x,
      mlineplot,
      ylabel={Statements in Millionen},
      xticklabel style={rotate=30, anchor=near xticklabel},
      ymin=0,
      scaled y ticks=base 10:-6,
      ytick scale label code/.code={},
      ]
      \addplot [blue] table [header=false, col sep=comma] {data/statements.csv} [yshift=-8pt]
      coordinate [pos=1] (end);
    \end{axis}
    \node[uncover=<2>,drawalert=<2>, anchor=west] (alert) at (4.5,2) {Mehr als 42GiB komprimiert};
    \draw[uncover=<2>, ->] (alert) -- (end);
  \end{tikzpicture}
      % \large{70 Millionen Items} \\
      % \vspace{0.3cm}
      % \large{800 Millionen Statements} \\
      % \vspace{0.3cm}
      % \large{vollständige Datendumps: \\mehr als 42GiB komprimiert}
\end{frame}

\end{document}
